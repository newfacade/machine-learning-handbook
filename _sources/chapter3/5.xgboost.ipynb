{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "Ensemble tree model:\n",
    "\n",
    "$$\\hat{y}_{i} = \\sum_{k=1}^{K}f_{k}(x_{i}), f_{k}\\in\\mathcal{F}$$\n",
    "\n",
    "The objective function:\n",
    "\n",
    "$$\\mbox{obj} = \\sum_{i=1}^{n}l(y_{i}, \\hat{y}_{i}) + \\sum_{k=1}^{K}\\Omega(f_{k})$$\n",
    "\n",
    "where $l$ is the loss term, $\\Omega$ is the regularization term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Order Objective\n",
    "\n",
    "Step by step:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mbox{obj}^{(t)} =& \\sum_{i=1}^{n}l(y_{i}, \\hat{y}_{i}^{(t)}) + \\sum_{k=1}^{t}\\Omega(f_{k}) \\\\\n",
    "=& \\sum_{i=1}^{n}l(y_{i}, \\hat{y}_{i}^{(t - 1)} + f_{t}(x_{i})) + \\Omega(f_{t}) + \\mbox{constant}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Take the taylor expansion up to the second order:\n",
    "\n",
    "$$\\mbox{obj}^{(t)} \\approx \\sum_{i=1}^{n}[l(y_{i}, \\hat{y}_{i}^{(t - 1)}) + g_{i}f_{t}(x_{i}) + \\frac{1}{2}h_{i}f_{t}(x_{i})^{2}] + \\Omega(f_{t}) + \\mbox{constant}$$\n",
    "\n",
    "$$g_{i} = \\frac{\\partial l(y_{i}, \\hat{y}_{i}^{(t - 1)})}{\\partial \\hat{y}_{i}^{(t-1)}}$$\n",
    "\n",
    "$$h_{i} = \\frac{\\partial^{2} l(y_{i}, \\hat{y}_{i}^{(t - 1)})}{{\\partial \\hat{y}_{i}^{(t-1)}}^2}$$\n",
    "\n",
    "After removing all the constants, the specific objective at step $t$ becomes:\n",
    "\n",
    "$$\\sum_{i=1}^{n}[g_{i}f_{t}(x_{i}) + \\frac{1}{2}h_{i}f_{t}(x_{i})^{2}] + \\Omega(f_{t})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Given Tree Structure\n",
    "\n",
    "We can define the complexity as ( $w_{j}$ is the value of the $j$-th leaf ):\n",
    "\n",
    "$$\\Omega(f_{t}) = \\gamma{T} + \\frac{1}{2}\\lambda\\sum_{j=1}^{T}w_{j}^{2}$$\n",
    "\n",
    "Rearrange the loss function:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mbox{obj}^{(t)} = & \\sum_{i=1}^{n}[g_{i}f_{t}(x_{i}) + \\frac{1}{2}h_{i}f_{t}(x_{i})^{2}] + \\gamma{T} + \\frac{1}{2}\\lambda\\sum_{j=1}^{T}w_{j}^{2} \\\\\n",
    "=& \\sum_{j=1}^{T}[(\\sum_{i\\in{I_{j}}}g_{i})w_{j} + \\frac{1}{2}(\\sum_{i\\in{I_j}}h_{i} + \\lambda)w_{j}^2] + \\gamma{T}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $I_{j} = \\{i|q_{i}=j\\}$ is the set of indices of data-points assign to the $j$-th leaf.\n",
    "\n",
    "Denote $G_{j} = \\sum_{i\\in{I_{j}}}g_{i}, H_{j} = \\sum_{i\\in{I_j}}h_{i}$:\n",
    "\n",
    "$$\\mbox{obj}^{(t)} = \\sum_{j=1}^{T}[G_{j}w_{j} + \\frac{1}{2}(H_{j} + \\lambda)w_{j}^2] + \\gamma{T}$$\n",
    "\n",
    "Quadratic optimization result:\n",
    "\n",
    "$$w_{j}^{\\ast} = -\\frac{G_{j}}{H_{j} + \\lambda}$$\n",
    "\n",
    "$$\\mbox{obj}^{\\ast} = -\\frac{1}{2}\\sum_{i=1}^{T}\\frac{G_{j}^2}{H_{j} + \\lambda} + \\gamma{T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Tree Structure\n",
    "\n",
    "When we try to split a leaf into two leaves, the score gain is:\n",
    "\n",
    "$$\\mbox{Gain} = \\frac{1}{2}\\left [\\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{(G_L + G_R)^2}{H_L + H_R + \\lambda}\\right ] - \\gamma$$\n",
    "\n",
    "Select split that maximize that Gain, thus form tree structure step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"quadratic dataset\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3 * X[:, 0] ** 2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"basic xgboost\"\"\"\n",
    "import xgboost\n",
    "\n",
    "reg = xgboost.XGBRegressor()\n",
    "reg.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
